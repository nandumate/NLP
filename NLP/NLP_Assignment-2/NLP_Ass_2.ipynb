{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment No.2**: Perform bag-of-words approach (count occurrence, normalized count occurrence), TF-IDF on data. Create embeddings using Word2Vec"
      ],
      "metadata": {
        "id": "zcSfF7RMPvz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries if not installed\n",
        "!pip install --upgrade gensim scikit-learn pandas numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiPGageXSpyx",
        "outputId": "3456498e-a271-4487-953a-b64ae6b4ad70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Using cached numpy-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
      ],
      "metadata": {
        "id": "pgH8_ZasUvA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset: List of documents\n",
        "documents = [\n",
        "    \"I love natural language processing and machine learning.\",\n",
        "    \"Machine learning is a fascinating field.\",\n",
        "    \"Deep learning and NLP are closely related.\",\n",
        "    \"Natural language processing is fun to learn.\",\n",
        "    \"I enjoy working with NLP and machine learning projects.\"\n",
        "]"
      ],
      "metadata": {
        "id": "BqQ0jZ9PU3dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function (without NLTK)\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation and numbers\n",
        "    tokens = text.split()  # Tokenization using split\n",
        "    tokens = [word for word in tokens if word not in ENGLISH_STOP_WORDS]  # Remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "preprocessed_docs = [preprocess_text(doc) for doc in documents]\n",
        "print(\"Preprocessed Documents:\\n\", preprocessed_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDbCO9O4U7_I",
        "outputId": "b3b30e39-4cd0-422d-b818-3f04079d6efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Documents:\n",
            " ['love natural language processing machine learning', 'machine learning fascinating field', 'deep learning nlp closely related', 'natural language processing fun learn', 'enjoy working nlp machine learning projects']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Bag of Words (BoW) ----\n",
        "vectorizer = CountVectorizer()\n",
        "bow_matrix = vectorizer.fit_transform(preprocessed_docs)\n",
        "bow_df = pd.DataFrame(bow_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "print(\"\\nBag-of-Words Matrix:\\n\", bow_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECuTdN_xVAIB",
        "outputId": "b99ecba3-42f3-4906-93a7-6d1a027601b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag-of-Words Matrix:\n",
            "    closely  deep  enjoy  fascinating  field  fun  language  learn  learning  \\\n",
            "0        0     0      0            0      0    0         1      0         1   \n",
            "1        0     0      0            1      1    0         0      0         1   \n",
            "2        1     1      0            0      0    0         0      0         1   \n",
            "3        0     0      0            0      0    1         1      1         0   \n",
            "4        0     0      1            0      0    0         0      0         1   \n",
            "\n",
            "   love  machine  natural  nlp  processing  projects  related  working  \n",
            "0     1        1        1    0           1         0        0        0  \n",
            "1     0        1        0    0           0         0        0        0  \n",
            "2     0        0        0    1           0         0        1        0  \n",
            "3     0        0        1    0           1         0        0        0  \n",
            "4     0        1        0    1           0         1        0        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- TF-IDF (Term Frequency - Inverse Document Frequency) ----\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_docs)\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "print(\"\\nTF-IDF Matrix:\\n\", tfidf_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyWXnLjaVDCu",
        "outputId": "0033dcc6-f466-41d5-a280-b6b4226593a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF Matrix:\n",
            "     closely      deep     enjoy  fascinating     field      fun  language  \\\n",
            "0  0.000000  0.000000  0.000000     0.000000  0.000000  0.00000  0.418378   \n",
            "1  0.000000  0.000000  0.000000     0.601285  0.601285  0.00000  0.000000   \n",
            "2  0.501992  0.501992  0.000000     0.000000  0.000000  0.00000  0.000000   \n",
            "3  0.000000  0.000000  0.000000     0.000000  0.000000  0.50298  0.405801   \n",
            "4  0.000000  0.000000  0.475822     0.000000  0.000000  0.00000  0.000000   \n",
            "\n",
            "     learn  learning      love   machine   natural       nlp  processing  \\\n",
            "0  0.00000  0.292153  0.518569  0.347292  0.418378  0.000000    0.418378   \n",
            "1  0.00000  0.338754  0.000000  0.402688  0.000000  0.000000    0.000000   \n",
            "2  0.00000  0.282814  0.000000  0.000000  0.000000  0.405004    0.000000   \n",
            "3  0.50298  0.000000  0.000000  0.000000  0.405801  0.000000    0.405801   \n",
            "4  0.00000  0.268070  0.000000  0.318664  0.000000  0.383890    0.000000   \n",
            "\n",
            "   projects   related   working  \n",
            "0  0.000000  0.000000  0.000000  \n",
            "1  0.000000  0.000000  0.000000  \n",
            "2  0.000000  0.501992  0.000000  \n",
            "3  0.000000  0.000000  0.000000  \n",
            "4  0.475822  0.000000  0.475822  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Word2Vec Embeddings ----\n",
        "tokenized_docs = [doc.split() for doc in preprocessed_docs]  # Tokenization\n",
        "word2vec_model = Word2Vec(sentences=tokenized_docs, vector_size=100, window=5, min_count=1, workers=4)\n"
      ],
      "metadata": {
        "id": "ncZTj5yTVGFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Get word embedding for 'learning'\n",
        "if 'learning' in word2vec_model.wv:\n",
        "    print(\"\\nWord2Vec Embedding for 'learning':\\n\", word2vec_model.wv['learning'])\n",
        "\n",
        "# Example: Find most similar words to 'nlp'\n",
        "if 'nlp' in word2vec_model.wv:\n",
        "    print(\"\\nMost Similar Words to 'nlp':\\n\", word2vec_model.wv.most_similar('nlp'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01p-_k8oVRee",
        "outputId": "be29c571-b1b0-412f-980e-343d61b81e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word2Vec Embedding for 'learning':\n",
            " [-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
            " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
            " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
            " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
            "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
            "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
            "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
            " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
            "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
            "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
            " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
            " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
            "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
            " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
            "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
            " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
            " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
            " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
            " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
            "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
            " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
            " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
            " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
            "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
            " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n",
            "\n",
            "Most Similar Words to 'nlp':\n",
            " [('closely', 0.16694684326648712), ('processing', 0.13888029754161835), ('language', 0.13149002194404602), ('natural', 0.06408820301294327), ('fascinating', 0.06059184670448303), ('love', 0.04767157509922981), ('fun', 0.04410678148269653), ('working', 0.020000355318188667), ('projects', 0.019152285531163216), ('machine', 0.009390447288751602)]\n"
          ]
        }
      ]
    }
  ]
}