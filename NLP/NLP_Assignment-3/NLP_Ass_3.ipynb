{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment No.3:** Perform text cleaning,perform lemmatization (any method) ,remove stop words(any method),label encoding create representations using TF-IDF save outputs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XqiRTQXHz9gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1️⃣ Import Libraries – pandas, nltk, string, sklearn.\n",
        "\n",
        "2️⃣ Download NLTK Resources – Stopwords & WordNet.\n",
        "\n",
        "3️⃣ Create DataFrame – Define text & label columns.\n",
        "\n",
        "4️⃣ Text Cleaning – Remove punctuation & convert to lowercase.\n",
        "\n",
        "5️⃣ Lemmatization & Stopword Removal – Tokenize, lemmatize & filter stopwords.\n",
        "\n",
        "6️⃣ Label Encoding – Convert categorical labels into numerical values.\n",
        "\n",
        "7️⃣ TF-IDF Representation – Convert processed_text into feature vectors.\n",
        "\n",
        "8️⃣ Save Outputs – Store cleaned data & TF-IDF matrix as CSV files.\n",
        "\n",
        "9️⃣ Display Results – Print processed text & TF-IDF matrix.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "UxqjKKiGFi8t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uJkyD4wwm9T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources if not already installed\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wgrgl1ABx-bJ",
        "outputId": "ff6ecb89-3b8d-4471-b87f-ee50d09c71cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "data = pd.DataFrame({\n",
        "    'text': [\n",
        "        'I love programming in Python!',\n",
        "        'Python is amazing for data analysis.',\n",
        "        'Data science is the future.',\n",
        "        'I hate bugs in my code.',\n",
        "        'Debugging is so frustrating.',\n",
        "        'The weather is nice today.',\n",
        "        'I need more coffee to focus.',\n",
        "        'The Python syntax is easy to learn.',\n",
        "        'JavaScript can be tricky to learn at first.',\n",
        "        'Data visualization is important in analysis.'\n",
        "    ],\n",
        "    'label': [\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'positive',\n",
        "        'negative',\n",
        "        'negative',\n",
        "        'neutral',\n",
        "        'neutral',\n",
        "        'positive',\n",
        "        'negative',\n",
        "        'neutral'\n",
        "    ]\n",
        "})"
      ],
      "metadata": {
        "id": "X6ButiEeyMhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Text Cleaning: Remove punctuation and make lowercase\n",
        "def clean_text(text):\n",
        "    # Remove punctuation and make text lowercase\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "data['cleaned_text'] = data['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "9GdvvFn_yOoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Lemmatization and Removing Stop Words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_and_remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    return ' '.join(lemmatized_words)\n",
        "\n",
        "# Apply lemmatization and stop word removal\n",
        "data['processed_text'] = data['cleaned_text'].apply(lemmatize_and_remove_stopwords)"
      ],
      "metadata": {
        "id": "1IyiarUqyUKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "data['encoded_label'] = label_encoder.fit_transform(data['label'])\n"
      ],
      "metadata": {
        "id": "Ltu2nd7VylXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TF-IDF Representation\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['processed_text'])\n",
        "\n",
        "# Convert TF-IDF matrix to DataFrame for easier viewing\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n"
      ],
      "metadata": {
        "id": "Qc5D1-k4yqUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the outputs to CSV files\n",
        "data.to_csv('cleaned_data.csv', index=False)\n",
        "tfidf_df.to_csv('tfidf_representation.csv', index=False)\n"
      ],
      "metadata": {
        "id": "6OFjQJObzs-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show outputs\n",
        "print(\"Processed DataFrame with Labels and Cleaned Text:\")\n",
        "print(data[['text', 'processed_text', 'encoded_label']])\n",
        "\n",
        "print(\"\\nTF-IDF Representation:\")\n",
        "print(tfidf_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLVWlmyQzzcA",
        "outputId": "26bf0748-c772-4638-c379-427985790f9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed DataFrame with Labels and Cleaned Text:\n",
            "                                           text  \\\n",
            "0                 I love programming in Python!   \n",
            "1          Python is amazing for data analysis.   \n",
            "2                   Data science is the future.   \n",
            "3                       I hate bugs in my code.   \n",
            "4                  Debugging is so frustrating.   \n",
            "5                    The weather is nice today.   \n",
            "6                  I need more coffee to focus.   \n",
            "7           The Python syntax is easy to learn.   \n",
            "8   JavaScript can be tricky to learn at first.   \n",
            "9  Data visualization is important in analysis.   \n",
            "\n",
            "                          processed_text  encoded_label  \n",
            "0                love programming python              2  \n",
            "1           python amazing data analysis              2  \n",
            "2                    data science future              2  \n",
            "3                          hate bug code              0  \n",
            "4                  debugging frustrating              0  \n",
            "5                     weather nice today              1  \n",
            "6                      need coffee focus              1  \n",
            "7               python syntax easy learn              2  \n",
            "8          javascript tricky learn first              0  \n",
            "9  data visualization important analysis              1  \n",
            "\n",
            "TF-IDF Representation:\n",
            "    amazing  analysis      bug     code  coffee      data  debugging  easy  \\\n",
            "0  0.000000  0.000000  0.00000  0.00000     0.0  0.000000   0.000000   0.0   \n",
            "1  0.594552  0.505423  0.00000  0.00000     0.0  0.442185   0.000000   0.0   \n",
            "2  0.000000  0.000000  0.00000  0.00000     0.0  0.465456   0.000000   0.0   \n",
            "3  0.000000  0.000000  0.57735  0.57735     0.0  0.000000   0.000000   0.0   \n",
            "4  0.000000  0.000000  0.00000  0.00000     0.0  0.000000   0.707107   0.0   \n",
            "\n",
            "   first  focus  ...  need  nice  programming    python  science  syntax  \\\n",
            "0    0.0    0.0  ...   0.0   0.0      0.62584  0.465456  0.00000     0.0   \n",
            "1    0.0    0.0  ...   0.0   0.0      0.00000  0.442185  0.00000     0.0   \n",
            "2    0.0    0.0  ...   0.0   0.0      0.00000  0.000000  0.62584     0.0   \n",
            "3    0.0    0.0  ...   0.0   0.0      0.00000  0.000000  0.00000     0.0   \n",
            "4    0.0    0.0  ...   0.0   0.0      0.00000  0.000000  0.00000     0.0   \n",
            "\n",
            "   today  tricky  visualization  weather  \n",
            "0    0.0     0.0            0.0      0.0  \n",
            "1    0.0     0.0            0.0      0.0  \n",
            "2    0.0     0.0            0.0      0.0  \n",
            "3    0.0     0.0            0.0      0.0  \n",
            "4    0.0     0.0            0.0      0.0  \n",
            "\n",
            "[5 rows x 27 columns]\n"
          ]
        }
      ]
    }
  ]
}